{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0275bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Allow notebook to find `src/` folder for imports\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "08b188bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction FG version: 2\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as c\n",
    "print(\"Prediction FG version:\", c.FEATURE_GROUP_MODEL_PREDICTION_VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8879c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import logging, sys\n",
    "import hopsworks\n",
    "\n",
    "from src.data_utils import (\n",
    "    load_and_process_citibike_data_from_local,\n",
    "    transform_raw_data_into_ts_data,\n",
    ")\n",
    "import src.config as config\n",
    "from hsfs.feature import Feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f3c220f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_utils import load_and_process_citibike_data_from_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "671a76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at the top of your notebook\n",
    "from src.data_utils import load_and_process_citibike_data_from_local\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "012957a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:12:27,628 INFO: üìÖ Loading Citi Bike data ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (5,7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:17:27,395 INFO: ‚úÖ Total rows loaded: 410,344\n",
      "['5329.03' '6140.05' '6948.10']\n",
      "            ride_id  rideable_type         pickup_datetime  \\\n",
      "0  A46D077151843D7B   classic_bike 2023-01-16 10:39:54.386   \n",
      "1  233875BAED2E02D0   classic_bike 2023-01-12 16:55:30.755   \n",
      "2  8DD222EA1A1B0BC9  electric_bike 2023-01-08 19:32:25.647   \n",
      "3  58976A4F584F8D28   classic_bike 2023-01-27 20:01:52.897   \n",
      "4  FDD4C1E89A26727C   classic_bike 2023-01-13 18:02:38.160   \n",
      "\n",
      "                  ended_at     start_station_name pickup_location_id  \\\n",
      "0  2023-01-16 10:45:18.005  West St & Chambers St            5329.03   \n",
      "1  2023-01-12 17:04:03.688  West St & Chambers St            5329.03   \n",
      "2  2023-01-08 19:42:00.382  West St & Chambers St            5329.03   \n",
      "3  2023-01-27 20:08:58.118  West St & Chambers St            5329.03   \n",
      "4  2023-01-13 18:11:22.139  West St & Chambers St            5329.03   \n",
      "\n",
      "  end_station_name end_station_id  start_lat  start_lng    end_lat    end_lng  \\\n",
      "0   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
      "1   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
      "2   West Thames St        5114.06  40.717618 -74.013071  40.708347 -74.017134   \n",
      "3   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
      "4   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
      "\n",
      "  member_casual                     source_file  \n",
      "0        member  202301-citibike-tripdata_1.csv  \n",
      "1        member  202301-citibike-tripdata_1.csv  \n",
      "2        member  202301-citibike-tripdata_1.csv  \n",
      "3        member  202301-citibike-tripdata_1.csv  \n",
      "4        member  202301-citibike-tripdata_1.csv  \n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s  %(levelname)s  %(message)s\", handlers=[logging.StreamHandler(sys.stdout)])\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "logger.info(\"üìÖ Loading Citi Bike data ‚Ä¶\")\n",
    "\n",
    "raw_rides_2023 = load_and_process_citibike_data_from_local(\n",
    "    year=2023,\n",
    "    months=list(range(1, 13)),\n",
    "    base_path=config.LOCAL_CITIBIKE_DATA_PATH\n",
    ")\n",
    "\n",
    "# raw_rides_2024 = load_and_process_citibike_data_from_local(\n",
    "#     year=2024,\n",
    "#     months=list(range(1, 13)),\n",
    "#     base_path=config.LOCAL_CITIBIKE_DATA_PATH\n",
    "# )\n",
    "\n",
    "# raw_rides_2025 = load_and_process_citibike_data_from_local(\n",
    "#     year=2025,\n",
    "#     months=[1, 2, 3],\n",
    "#     base_path=config.LOCAL_CITIBIKE_DATA_PATH\n",
    "# )\n",
    "\n",
    "raw_rides = pd.concat([raw_rides_2023])\n",
    "\n",
    "# raw_rides = pd.concat([raw_rides_2023, raw_rides_2024, raw_rides_2025])\n",
    "logger.info(f\"‚úÖ Total rows loaded: {len(raw_rides):,}\")\n",
    "\n",
    "print(raw_rides[\"pickup_location_id\"].unique())\n",
    "\n",
    "print(raw_rides.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ced5443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:17:52,852 INFO: üìâ Filtered for top 3 stations: 410,344 rows\n"
     ]
    }
   ],
   "source": [
    "TOP_3_IDS = {\"6140.05\", \"6948.10\", \"5329.03\"}\n",
    "\n",
    "raw_rides_top3 = raw_rides[raw_rides[\"pickup_location_id\"].astype(str).isin(TOP_3_IDS)].copy()\n",
    "logger.info(f\"üìâ Filtered for top 3 stations: {len(raw_rides_top3):,} rows\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6852dfc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A46D077151843D7B</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-16 10:39:54.386</td>\n",
       "      <td>2023-01-16 10:45:18.005</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>233875BAED2E02D0</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-12 16:55:30.755</td>\n",
       "      <td>2023-01-12 17:04:03.688</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8DD222EA1A1B0BC9</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2023-01-08 19:32:25.647</td>\n",
       "      <td>2023-01-08 19:42:00.382</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717618</td>\n",
       "      <td>-74.013071</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58976A4F584F8D28</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-27 20:01:52.897</td>\n",
       "      <td>2023-01-27 20:08:58.118</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDD4C1E89A26727C</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2023-01-13 18:02:38.160</td>\n",
       "      <td>2023-01-13 18:11:22.139</td>\n",
       "      <td>West St &amp; Chambers St</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>West Thames St</td>\n",
       "      <td>5114.06</td>\n",
       "      <td>40.717548</td>\n",
       "      <td>-74.013221</td>\n",
       "      <td>40.708347</td>\n",
       "      <td>-74.017134</td>\n",
       "      <td>member</td>\n",
       "      <td>202301-citibike-tripdata_1.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ride_id  rideable_type         pickup_datetime  \\\n",
       "0  A46D077151843D7B   classic_bike 2023-01-16 10:39:54.386   \n",
       "1  233875BAED2E02D0   classic_bike 2023-01-12 16:55:30.755   \n",
       "2  8DD222EA1A1B0BC9  electric_bike 2023-01-08 19:32:25.647   \n",
       "3  58976A4F584F8D28   classic_bike 2023-01-27 20:01:52.897   \n",
       "4  FDD4C1E89A26727C   classic_bike 2023-01-13 18:02:38.160   \n",
       "\n",
       "                  ended_at     start_station_name pickup_location_id  \\\n",
       "0  2023-01-16 10:45:18.005  West St & Chambers St            5329.03   \n",
       "1  2023-01-12 17:04:03.688  West St & Chambers St            5329.03   \n",
       "2  2023-01-08 19:42:00.382  West St & Chambers St            5329.03   \n",
       "3  2023-01-27 20:08:58.118  West St & Chambers St            5329.03   \n",
       "4  2023-01-13 18:11:22.139  West St & Chambers St            5329.03   \n",
       "\n",
       "  end_station_name end_station_id  start_lat  start_lng    end_lat    end_lng  \\\n",
       "0   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "1   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "2   West Thames St        5114.06  40.717618 -74.013071  40.708347 -74.017134   \n",
       "3   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "4   West Thames St        5114.06  40.717548 -74.013221  40.708347 -74.017134   \n",
       "\n",
       "  member_casual                     source_file  \n",
       "0        member  202301-citibike-tripdata_1.csv  \n",
       "1        member  202301-citibike-tripdata_1.csv  \n",
       "2        member  202301-citibike-tripdata_1.csv  \n",
       "3        member  202301-citibike-tripdata_1.csv  \n",
       "4        member  202301-citibike-tripdata_1.csv  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rides_top3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ca6bfdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:17:55,562 INFO: üßÆ Aggregating to hourly time-series format ‚Ä¶\n",
      "2025-05-10 04:17:55,862 INFO: ‚úÖ Transformed data shape: (26535, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-12-28 11:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-12-28 12:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-12-28 13:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-12-28 14:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-12-28 15:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour pickup_location_id  rides\n",
       "0 2022-12-28 11:00:00            5329.03      2\n",
       "1 2022-12-28 12:00:00            5329.03      0\n",
       "2 2022-12-28 13:00:00            5329.03      0\n",
       "3 2022-12-28 14:00:00            5329.03      0\n",
       "4 2022-12-28 15:00:00            5329.03      0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logger.info(\"üßÆ Aggregating to hourly time-series format ‚Ä¶\")\n",
    "ts_data = transform_raw_data_into_ts_data(raw_rides_top3)\n",
    "logger.info(f\"‚úÖ Transformed data shape: {ts_data.shape}\")\n",
    "ts_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ee591a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:18:01,609 INFO: üîê Logging in to Hopsworks ‚Ä¶\n",
      "2025-05-10 04:18:01,612 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 04:18:01,638 INFO: Initializing external client\n",
      "2025-05-10 04:18:01,639 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.8 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:18:02,548 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214682\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"üîê Logging in to Hopsworks ‚Ä¶\")\n",
    "project = hopsworks.login(\n",
    "    project=config.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value=config.HOPSWORKS_API_KEY,\n",
    ")\n",
    "fs = project.get_feature_store()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ecffb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:18:23,847 INFO: üì¶ Writing to Hopsworks feature group ‚Ä¶\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 26535/26535 | Elapsed Time: 00:04 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citibike_hourly_features_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214682/jobs/named/citibike_hourly_features_1_offline_fg_materialization/executions\n",
      "2025-05-10 04:19:05,604 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-10 04:19:18,037 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-10 04:21:13,240 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-05-10 04:21:13,329 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-10 04:21:24,963 INFO: Execution finished successfully.\n",
      "2025-05-10 04:21:24,964 INFO: ‚úÖ Done uploading data to Hopsworks!\n"
     ]
    }
   ],
   "source": [
    "from hsfs.feature import Feature\n",
    "\n",
    "fg_schema = [\n",
    "    Feature(\"pickup_hour\",        \"timestamp\"),\n",
    "    Feature(\"pickup_location_id\", \"string\"),\n",
    "    Feature(\"rides\",              \"int\"),\n",
    "]\n",
    "\n",
    "logger.info(\"üì¶ Writing to Hopsworks feature group ‚Ä¶\")\n",
    "hourly_fg = fs.get_or_create_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION,\n",
    "    description=\"Hourly Citi Bike rides per location (2023)\",\n",
    "    primary_key=[\"pickup_hour\", \"pickup_location_id\"],\n",
    "    event_time=\"pickup_hour\",\n",
    "    online_enabled=False,\n",
    "    features=fg_schema,\n",
    ")\n",
    "\n",
    "ts_data[\"pickup_location_id\"] = ts_data[\"pickup_location_id\"].astype(str)\n",
    "ts_data[\"rides\"] = ts_data[\"rides\"].astype(\"int64\")  # <- updated here\n",
    "\n",
    "hourly_fg.insert(ts_data, write_options={\"wait_for_job\": True})\n",
    "logger.info(\"‚úÖ Done uploading data to Hopsworks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be755da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:21:51,087 INFO: üîé Creating Feature View ‚Ä¶\n",
      "2025-05-10 04:21:52,031 INFO: ‚úÖ Feature View created successfully.\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"üîé Creating Feature View ‚Ä¶\")\n",
    "\n",
    "from hsfs.feature import Feature\n",
    "\n",
    "feature_group = fs.get_feature_group(\n",
    "    name=config.FEATURE_GROUP_NAME,\n",
    "    version=config.FEATURE_GROUP_VERSION\n",
    ")\n",
    "\n",
    "feature_view = fs.get_or_create_feature_view(\n",
    "    name=config.FEATURE_VIEW_NAME,\n",
    "    version=config.FEATURE_VIEW_VERSION,\n",
    "    description=\"Feature view for Citi Bike hourly demand\",\n",
    "    labels=[],\n",
    "    query=feature_group.select_all()\n",
    ")\n",
    "\n",
    "logger.info(\"‚úÖ Feature View created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a0c2030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:21:54,208 INFO: üìä Generating sliding window features ‚Ä¶\n",
      "‚úÖ Transformed shape: (24519, 675)\n",
      "‚úÖ Sample columns: ['rides_t-672', 'rides_t-671', 'rides_t-670', 'rides_t-669', 'rides_t-668', '...', 'target', 'pickup_hour', 'pickup_location_id']\n"
     ]
    }
   ],
   "source": [
    "from src.data_utils import transform_ts_data_info_features_and_target_loop\n",
    "\n",
    "logger.info(\"üìä Generating sliding window features ‚Ä¶\")\n",
    "\n",
    "# Use correct window size\n",
    "window_size = 672\n",
    "\n",
    "# Get full transformed DataFrame with all metadata\n",
    "features_df, _ = transform_ts_data_info_features_and_target_loop(\n",
    "    ts_data, feature_col=\"rides\", window_size=window_size, step_size=1\n",
    ")\n",
    "\n",
    "# Check shape and available columns\n",
    "print(\"‚úÖ Transformed shape:\", features_df.shape)\n",
    "print(\"‚úÖ Sample columns:\", features_df.columns[:5].tolist() + [\"...\", features_df.columns[-3], features_df.columns[-2], features_df.columns[-1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe1df65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rides_t-672</th>\n",
       "      <th>rides_t-671</th>\n",
       "      <th>rides_t-670</th>\n",
       "      <th>rides_t-669</th>\n",
       "      <th>rides_t-668</th>\n",
       "      <th>rides_t-667</th>\n",
       "      <th>rides_t-666</th>\n",
       "      <th>rides_t-665</th>\n",
       "      <th>rides_t-664</th>\n",
       "      <th>rides_t-663</th>\n",
       "      <th>...</th>\n",
       "      <th>rides_t-7</th>\n",
       "      <th>rides_t-6</th>\n",
       "      <th>rides_t-5</th>\n",
       "      <th>rides_t-4</th>\n",
       "      <th>rides_t-3</th>\n",
       "      <th>rides_t-2</th>\n",
       "      <th>rides_t-1</th>\n",
       "      <th>target</th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-01-25 11:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-01-25 12:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2023-01-25 13:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2023-01-25 14:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-01-25 15:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 675 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rides_t-672  rides_t-671  rides_t-670  rides_t-669  rides_t-668  \\\n",
       "0            2            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   rides_t-667  rides_t-666  rides_t-665  rides_t-664  rides_t-663  ...  \\\n",
       "0            0            0            0            0            0  ...   \n",
       "1            0            0            0            0            0  ...   \n",
       "2            0            0            0            0            0  ...   \n",
       "3            0            0            0            0            0  ...   \n",
       "4            0            0            0            0            0  ...   \n",
       "\n",
       "   rides_t-7  rides_t-6  rides_t-5  rides_t-4  rides_t-3  rides_t-2  \\\n",
       "0          0          0          8         18         20         16   \n",
       "1          0          8         18         20         16          7   \n",
       "2          8         18         20         16          7          6   \n",
       "3         18         20         16          7          6          3   \n",
       "4         20         16          7          6          3          6   \n",
       "\n",
       "   rides_t-1  target         pickup_hour  pickup_location_id  \n",
       "0          7       6 2023-01-25 11:00:00             5329.03  \n",
       "1          6       3 2023-01-25 12:00:00             5329.03  \n",
       "2          3       6 2023-01-25 13:00:00             5329.03  \n",
       "3          6       4 2023-01-25 14:00:00             5329.03  \n",
       "4          4       0 2023-01-25 15:00:00             5329.03  \n",
       "\n",
       "[5 rows x 675 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "acf66496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for model at: c:\\Users\\mahmo\\OneDrive\\Desktop\\Spring 2025\\MLops notes\\Final_Project\\Final_Project\\notebooks\\..\\models\\lgb_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"Looking for model at:\", model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5f8afd3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ûú Trained model expected 675 features\n",
      "First 5: ['rides_t-672', 'rides_t-671', 'rides_t-670', 'rides_t-669', 'rides_t-668']\n",
      "Last 5:  ['rides_t-2', 'rides_t-1', 'average_rides_last_4_weeks', 'hour', 'day_of_week']\n",
      "‚ûú Your X has 674 columns.\n",
      "First 5: ['rides_t-672', 'rides_t-671', 'rides_t-670', 'rides_t-669', 'rides_t-668']\n",
      "Last 5:  ['rides_t-3', 'rides_t-2', 'rides_t-1', 'pickup_hour', 'pickup_location_id']\n",
      "‚úñ Features expected by model but missing in X: ['average_rides_last_4_weeks', 'day_of_week', 'hour']\n",
      "‚úñ Extra columns in X that the model didn‚Äôt expect: ['pickup_hour', 'pickup_location_id']\n"
     ]
    }
   ],
   "source": [
    "# 0Ô∏è‚É£ load the full Pipeline\n",
    "import os, sys, joblib\n",
    "\n",
    "model_path = os.path.abspath(\n",
    "    os.path.join(os.getcwd(), \"..\", \"models\", \"lgb_model.pkl\")\n",
    ")\n",
    "lgb_pipeline = joblib.load(model_path)\n",
    "\n",
    "# 1Ô∏è‚É£ pull out the underlying Booster and its feature‚Äêname list\n",
    "#   (depends on whether you have a plain LGBMModel or a sklearn Pipeline)\n",
    "if hasattr(lgb_pipeline, \"booster_\"):\n",
    "    booster = lgb_pipeline.booster_\n",
    "elif hasattr(lgb_pipeline, \"_Booster\"):\n",
    "    booster = lgb_pipeline._Booster\n",
    "else:\n",
    "    # assume a Pipeline and last step is the LGB\n",
    "    booster = lgb_pipeline.steps[-1][1].booster_\n",
    "\n",
    "expected = booster.feature_name()\n",
    "print(\"‚ûú Trained model expected\", len(expected), \"features\")\n",
    "print(\"First 5:\", expected[:5])\n",
    "print(\"Last 5: \", expected[-5:])\n",
    "\n",
    "# 2Ô∏è‚É£ build your X exactly as you have it now\n",
    "lag_cols   = [c for c in features_df.columns if c.startswith(\"rides_t-\")]\n",
    "input_cols = lag_cols + [\"pickup_hour\", \"pickup_location_id\"]\n",
    "X = features_df[input_cols]\n",
    "\n",
    "print(\"‚ûú Your X has\", X.shape[1], \"columns.\")\n",
    "print(\"First 5:\", X.columns[:5].tolist())\n",
    "print(\"Last 5: \", X.columns[-5:].tolist())\n",
    "\n",
    "# 3Ô∏è‚É£ see which names don‚Äôt line up\n",
    "missing_in_X   = set(expected) - set(X.columns)\n",
    "extra_in_X     = set(X.columns) - set(expected)\n",
    "print(\"‚úñ Features expected by model but missing in X:\", sorted(missing_in_X))\n",
    "print(\"‚úñ Extra columns in X that the model didn‚Äôt expect:\", sorted(extra_in_X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7eec5b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>predicted_rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-25 11:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>5.419731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-25 12:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>5.569593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-25 13:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>7.608118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-25 14:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>12.339712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-25 15:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>12.071121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour pickup_location_id  predicted_rides\n",
       "0 2023-01-25 11:00:00            5329.03         5.419731\n",
       "1 2023-01-25 12:00:00            5329.03         5.569593\n",
       "2 2023-01-25 13:00:00            5329.03         7.608118\n",
       "3 2023-01-25 14:00:00            5329.03        12.339712\n",
       "4 2023-01-25 15:00:00            5329.03        12.071121"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 1Ô∏è‚É£ Locate & load your full pipeline (with featurizer + LGB):\n",
    "model_path = os.path.abspath(\n",
    "    os.path.join(os.getcwd(), \"..\", \"models\", \"lgb_model.pkl\")\n",
    ")\n",
    "pipeline = joblib.load(model_path)\n",
    "\n",
    "# 2Ô∏è‚É£ Build the raw X exactly as the pipeline saw it at train time:\n",
    "lag_cols = [c for c in features_df.columns if c.startswith(\"rides_t-\")]\n",
    "\n",
    "X_raw = features_df[ \n",
    "    lag_cols\n",
    "    + [ \"pickup_hour\", \"pickup_location_id\"]\n",
    "].copy()\n",
    "\n",
    "# 3Ô∏è‚É£ Now run it:\n",
    "preds = pipeline.predict(X_raw)\n",
    "\n",
    "# 4Ô∏è‚É£ Stick them back:\n",
    "features_df = features_df.copy()\n",
    "features_df[\"predicted_rides\"] = preds\n",
    "\n",
    "features_df[[\"pickup_hour\", \"pickup_location_id\", \"predicted_rides\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8207b47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>predicted_rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-25 11:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-25 12:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-25 13:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-25 14:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-25 15:00:00</td>\n",
       "      <td>5329.03</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour pickup_location_id  predicted_rides\n",
       "0 2023-01-25 11:00:00            5329.03                5\n",
       "1 2023-01-25 12:00:00            5329.03                6\n",
       "2 2023-01-25 13:00:00            5329.03                8\n",
       "3 2023-01-25 14:00:00            5329.03               12\n",
       "4 2023-01-25 15:00:00            5329.03               12"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, sys, joblib\n",
    "import pandas as pd\n",
    "\n",
    "# 0Ô∏è‚É£ If you haven‚Äôt already, make sure your notebook can see ../models\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# 1Ô∏è‚É£ Load the full sklearn Pipeline you trained\n",
    "model_path = os.path.join(os.getcwd(), \"..\", \"models\", \"lgb_model.pkl\")\n",
    "assert os.path.exists(model_path), f\"Model not found: {model_path}\"\n",
    "pipeline = joblib.load(model_path)\n",
    "\n",
    "# 2Ô∏è‚É£ Build the raw X exactly as your pipeline saw it at train time:\n",
    "#    - ALL lag features (\"rides_t-...\") \n",
    "#    - the placeholder \"target\" column (pipeline will drop it internally)\n",
    "#    - pickup_hour (for hour/day features)\n",
    "#    - pickup_location_id (so the pipeline‚Äôs drop-step can find it)\n",
    "lag_cols = [col for col in features_df.columns if col.startswith(\"rides_t-\")]\n",
    "X_raw   = features_df[lag_cols + [ \"pickup_hour\", \"pickup_location_id\"]].copy()\n",
    "\n",
    "# 3Ô∏è‚É£ Run the pipeline‚Äôs predict (it will extend with avg/day/hour, drop extras, then LGBM)\n",
    "preds = pipeline.predict(X_raw)\n",
    "\n",
    "# 4Ô∏è‚É£ Round to int32 (since your FG schema is `int`)\n",
    "features_df = features_df.copy()  # avoid any warning\n",
    "features_df[\"predicted_rides\"] = preds.round(0).astype(\"int32\")\n",
    "\n",
    "# 5Ô∏è‚É£ Quick sanity check\n",
    "features_df[[\"pickup_hour\", \"pickup_location_id\", \"predicted_rides\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d443097f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24519, 676)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5dc4d78f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pickup_hour pickup_location_id  predicted_rides\n",
      "0 2023-01-25 11:00:00            5329.03                5\n",
      "1 2023-01-25 12:00:00            5329.03                6\n",
      "2 2023-01-25 13:00:00            5329.03                8\n",
      "3 2023-01-25 14:00:00            5329.03               12\n",
      "4 2023-01-25 15:00:00            5329.03               12\n"
     ]
    }
   ],
   "source": [
    "# quick sanity‚Äëcheck\n",
    "print(features_df[[\"pickup_hour\", \"pickup_location_id\", \"predicted_rides\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "38862702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction FG version: 2\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "import src.config as c\n",
    "print(\"Prediction FG version:\", c.FEATURE_GROUP_MODEL_PREDICTION_VERSION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2aec7908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:24:08,686 INFO: Closing external client and cleaning up certificates.\n",
      "Connection closed.\n",
      "2025-05-10 04:24:08,691 INFO: Initializing external client\n",
      "2025-05-10 04:24:08,692 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "UserWarning: The installed hopsworks client version 4.1.8 may not be compatible with the connected Hopsworks backend version 4.2.0. \n",
      "To ensure compatibility please install the latest bug fix release matching the minor version of your backend (4.2) by running 'pip install hopsworks==4.2.*'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-10 04:24:09,664 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1214682\n",
      "‚úÖ Using Feature Group ‚Äúciti_bike_prediction‚Äù v2 (id None)\n",
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1214682/fs/1202313/fg/1454574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 24519/24519 | Elapsed Time: 00:03 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: citi_bike_prediction_2_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1214682/jobs/named/citi_bike_prediction_2_offline_fg_materialization/executions\n",
      "2025-05-10 04:24:26,901 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-05-10 04:24:30,005 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-05-10 04:26:40,583 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-05-10 04:26:40,690 INFO: Waiting for log aggregation to finish.\n",
      "2025-05-10 04:26:49,023 INFO: Execution finished successfully.\n",
      "üöÄ  Predictions uploaded to Hopsworks!\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "from hsfs.feature import Feature\n",
    "import src.config as c\n",
    "\n",
    "# 1Ô∏è‚É£ Log in\n",
    "project = hopsworks.login(\n",
    "    project       = c.HOPSWORKS_PROJECT_NAME,\n",
    "    api_key_value = c.HOPSWORKS_API_KEY,\n",
    ")\n",
    "fs = project.get_feature_store()\n",
    "\n",
    "# 2Ô∏è‚É£ Get-or-create the prediction Feature Group v2\n",
    "pred_fg = fs.get_or_create_feature_group(\n",
    "    name          = c.FEATURE_GROUP_MODEL_PREDICTION,\n",
    "    version       = c.FEATURE_GROUP_MODEL_PREDICTION_VERSION,\n",
    "    description   = \"Next-hour demand predictions from LGBM model (v2)\",\n",
    "    primary_key   = [\"pickup_location_id\", \"pickup_hour\"],\n",
    "    event_time    = \"pickup_hour\",\n",
    "    online_enabled=False,\n",
    "    features      = [\n",
    "        Feature(\"pickup_location_id\", \"string\"),\n",
    "        Feature(\"pickup_hour\",        \"timestamp\"),\n",
    "        Feature(\"predicted_rides\",    \"int\"),\n",
    "    ],\n",
    ")\n",
    "print(f\"‚úÖ Using Feature Group ‚Äú{pred_fg.name}‚Äù v{pred_fg.version} (id {pred_fg.id})\")\n",
    "\n",
    "# 3Ô∏è‚É£ Prepare your output DataFrame exactly to schema\n",
    "out_df = features_df[[\"pickup_hour\", \"pickup_location_id\", \"predicted_rides\"]].copy()\n",
    "out_df[\"pickup_location_id\"] = out_df[\"pickup_location_id\"].astype(str)\n",
    "out_df[\"predicted_rides\"]    = out_df[\"predicted_rides\"].round(0).astype(\"int32\")\n",
    "\n",
    "# 4Ô∏è‚É£ Insert & wait for completion\n",
    "pred_fg.insert(out_df, write_options={\"wait_for_job\": True})\n",
    "print(\"üöÄ  Predictions uploaded to Hopsworks!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bcb0d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
